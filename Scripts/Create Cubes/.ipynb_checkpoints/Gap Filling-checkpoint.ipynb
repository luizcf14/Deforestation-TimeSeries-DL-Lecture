{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gap filling of the dta cube stacks\n",
    "\n",
    "## 1. Importing libraries\n",
    "\n",
    "Libraries reference:\n",
    "\n",
    "+ [numpy](https://numpy.org/install/)\n",
    "+ [scipy](https://www.scipy.org/install.html)\n",
    "+ [rasterio](https://rasterio.readthedocs.io/en/latest/)\n",
    "+ [tqdm](https://github.com/tqdm/tqdm)\n",
    "+ [os](https://docs.python.org/3/library/os.html)\n",
    "+ [gdal](https://gdal.org/api/python.html)\n",
    "+ [multiprocessing](https://docs.python.org/3/library/multiprocessing.html)\n",
    "+ [functools](https://docs.python.org/3/library/functools.html)\n",
    "+ [datetime](https://docs.python.org/3/library/datetime.html)\n",
    "+ [time](https://docs.python.org/3/library/time.html)\n",
    "+ [glob](https://docs.python.org/3/library/glob.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "import rasterio as r\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import gdal\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import datetime\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Changing working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where all data is stored\n",
    "os.chdir(os.getcwd().rsplit('/',2)[0]+'/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the gap filling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CubicSpline(ts, days, bc_t, extrap):\n",
    "    # ts = time series with clouds\n",
    "    # days = day entry for each ts entry. must be crescent.\n",
    "    # bc_t = CubicSpline bc_type. Boundary condition type. natural\n",
    "    # extrap = CubicSpline extrapolate. bool\n",
    "    # result = filtered time series\n",
    "\n",
    "    # 'true' is where there is invalid pixels\n",
    "    pqa = ts==-9999\n",
    "\n",
    "    # x1: array for the Spline function\n",
    "    x1 = days[np.invert(pqa)]\n",
    "\n",
    "    # y1: array for the Spline function\n",
    "    y1 = ts[np.invert(pqa)]\n",
    "    \n",
    "    if len(x1)>1:\n",
    "        # the spline interpolator\n",
    "        spline = interpolate.CubicSpline(x1,y1, bc_type=bc_t, extrapolate=extrap)\n",
    "\n",
    "        # x values to interpolate\n",
    "        x2 = np.where(pqa==True)\n",
    "\n",
    "        result = ts.copy()\n",
    "        for index in x2:\n",
    "            result[index] = spline(days[index])\n",
    "            \n",
    "        return result\n",
    "    else:\n",
    "        return [-9999]*len(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filling the gaps in the data cube stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating folder to save filled cubes.\n",
    "os.mkdir('./cubes/filled')\n",
    "\n",
    "# collect cubes that need filling.\n",
    "cubes = [file for file in glob.glob('./cubes/raw/*.tif') if not 'Fmask4' in file]\n",
    "\n",
    "# iterate through the cubes to be filled.\n",
    "for cube_path in cubes:\n",
    "    ################\n",
    "    # START PROCESSING THE CUBES\n",
    "    ################\n",
    "    t1 = time.time()\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('                  PROCESSING '+cube_path)\n",
    "    \n",
    "    ################\n",
    "    # DAYS\n",
    "    ################\n",
    "    days_path = f'./cubes/raw/days.{cube_path.split(\".\")[1].split(\"/\")[-1]}.{cube_path.split(\".\")[-3]}.npy'\n",
    "\n",
    "    days = np.load(days_path)\n",
    "\n",
    "    days2 = []\n",
    "    aux1 = datetime.datetime.strptime(days[0], '%Y-%m-%d')\n",
    "    days2.append(0)\n",
    "    for i in range(1, len(days)):\n",
    "        aux2 = datetime.datetime.strptime(days[i], '%Y-%m-%d')\n",
    "        days2.append(days2[i-1]+(aux2-aux1).days)\n",
    "        aux1 = aux2\n",
    "\n",
    "    days = np.asarray(days2)\n",
    "    del days2\n",
    "\n",
    "    ################\n",
    "    # LOADING FMASK\n",
    "    ################\n",
    "    print('Loading mask...')\n",
    "\n",
    "    fmask_path = cube_path.replace(cube_path.split(\".\")[-2], 'Fmask4')\n",
    "    fmask = r.open(fmask_path).read()\n",
    "    a = fmask==0\n",
    "    b = fmask==1\n",
    "\n",
    "    mask = a+b\n",
    "    del fmask, a, b\n",
    "\n",
    "    ##################\n",
    "    # SAVE PATH\n",
    "    ##################\n",
    "    save_path = cube_path.replace('raw', 'filled')\n",
    "\n",
    "    ################\n",
    "    # LOADING CUBE\n",
    "    ################\n",
    "    print('Loading Cube '+cube_path+'...')\n",
    "\n",
    "    cube = np.asarray(r.open(cube_path).read())\n",
    "    cube[np.invert(mask)] = -9999\n",
    "\n",
    "    ################\n",
    "    # PROCESSING\n",
    "    ################\n",
    "    print('Processing...')\n",
    "\n",
    "    n = cube.shape[0]\n",
    "    series_to_process = []\n",
    "    ij = []\n",
    "    count = 0\n",
    "    n_to_process = 1000000\n",
    "    for i in tqdm(range(cube.shape[1])):\n",
    "        for j in range(cube.shape[2]):\n",
    "            series_to_process.append(cube[:,i,j])\n",
    "            ij.append([i,j])\n",
    "            count +=1\n",
    "\n",
    "            if count == n_to_process or (i==cube.shape[1]-1 and j==cube.shape[2]-1):\n",
    "                with mp.Pool(processes=mp.cpu_count()-10) as pool:\n",
    "                    result_series = pool.starmap(partial(CubicSpline), [(series_to_process[k], days, 'natural', bool) for k in range(len(ij))])\n",
    "                for k in range(len(ij)):\n",
    "                    cube[:,ij[k][0],ij[k][1]] = result_series[k]\n",
    "\n",
    "                count = 0\n",
    "                series_to_process = []\n",
    "                ij = []\n",
    "\n",
    "    ################\n",
    "    # SAVING\n",
    "    ################\n",
    "    print('Saving...')\n",
    "\n",
    "    ref2 = gdal.Open(cube_path)\n",
    "    in_band = ref2.GetRasterBand(1)\n",
    "\n",
    "    gtiff_driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    print('File Location: '+save_path)\n",
    "\n",
    "    out_ds = gtiff_driver.Create(save_path, in_band.XSize, in_band.YSize, cube.shape[0], in_band.DataType, ['COMPRESSION=LZW'])\n",
    "    out_ds.SetProjection(ref2.GetProjection())\n",
    "    out_ds.SetGeoTransform(ref2.GetGeoTransform())\n",
    "\n",
    "    for i in range(1, cube.shape[0]+1, 1):\n",
    "        band = out_ds.GetRasterBand(i)\n",
    "        band.SetNoDataValue(-9999)\n",
    "        band.WriteArray(cube[i-1,:,:])\n",
    "        band.FlushCache()\n",
    "\n",
    "    out_ds = None\n",
    "    ref2 = None\n",
    "    t2 = time.time()\n",
    "    print('Elapsed time: %.3f minutes\\nDone!'%((t2-t1)/60))\n",
    "\n",
    "print('---------------------------------------------------------\\nAll done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
