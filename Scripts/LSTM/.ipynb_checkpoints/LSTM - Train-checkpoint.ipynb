{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the LSTM Model\n",
    "\n",
    "This script aims to conduct the training phase of the LSTM. In this case the training samples were previously selected by another script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries and change working directory\n",
    "\n",
    "Reference for the libraries:\n",
    "\n",
    "+ [numpy](https://numpy.org/)\n",
    "+ [collections](https://docs.python.org/3/library/collections.html)\n",
    "+ [tensorflow](https://www.tensorflow.org/)\n",
    "+ [keras](https://keras.io/)\n",
    "+ [datetime](https://docs.python.org/3/library/datetime.html)\n",
    "+ [sklearn](https://scikit-learn.org/stable/)\n",
    "+ [matplotlib](https://matplotlib.org/)\n",
    "+ [os](https://docs.python.org/3/library/os.html)\n",
    "+ [time](https://docs.python.org/3/library/time.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from os import makedirs\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing important information and aquires the starting point of the script in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print('Tensorflow Version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where all data is stored\n",
    "os.chdir(os.getcwd().rsplit('/',2)[0]+'/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creates the identifier and logdir for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "identifier = '{0}-{1}-{2}_{3}-{4}-{5}'.format(now.year, \n",
    "                                              str(now.month).zfill(2), \n",
    "                                              str(now.day).zfill(2), \n",
    "                                              str(now.hour).zfill(2), \n",
    "                                              str(now.minute).zfill(2), \n",
    "                                              str(now.second).zfill(2))\n",
    "\n",
    "print('Identifier:', identifier)\n",
    "print('Tensorboard Location:', '/logs/fit/'+identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the notebook to the logs folder, in order to track what parameters and architecture were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs('/home/bruno.matosak/logs/fit/' + identifier, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples_series = np.load('./training_samples/LSTM/appr1.BA.2019.samples.npy')\n",
    "training_samples_truth  = np.load('./training_samples/LSTM/appr1.BA.2019.truth.npy')\n",
    "\n",
    "ind_fist_day = 0\n",
    "ind_last_day = 85\n",
    "\n",
    "# Trimming to specific time interval and correcting reference\n",
    "print('Training Samples Shape:', training_samples_series.shape)\n",
    "training_samples_series = training_samples_series[:,ind_fist_day:ind_last_day,:]\n",
    "print('Training Samples Shape Trimmed:', training_samples_series.shape)\n",
    "\n",
    "# training_samples_truth = training_samples_truth[:,2]\n",
    "print('Reference Shape', training_samples_truth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "input_dim = training_samples_series.shape[2]\n",
    "\n",
    "units = 256\n",
    "output_size = 2  # labels are of one dimension\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "  # CuDNN is only available at the layer level, and not at the cell level.\n",
    "  # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "  # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "  if allow_cudnn_kernel:\n",
    "    # The LSTM layer with default options uses CuDNN.\n",
    "    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "  else:\n",
    "    # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "    lstm_layer = tf.keras.layers.RNN(\n",
    "        tf.keras.layers.LSTMCell(units),\n",
    "        input_shape=(None, input_dim))\n",
    "  model = tf.keras.models.Sequential([\n",
    "      lstm_layer,\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(output_size, activation='softmax')])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Separate Train and Validate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_shape = training_samples_series.shape\n",
    "\n",
    "x_train = training_samples_series[0:int(ts_shape[0]*.8), :, :].copy()\n",
    "x_test  = training_samples_series[int(ts_shape[0]*.8):int(ts_shape[0]), :, :].copy()\n",
    "\n",
    "y_train = training_samples_truth[0:int(ts_shape[0]*.8)].copy()\n",
    "y_test  = training_samples_truth[int(ts_shape[0]*.8):int(ts_shape[0])].copy()\n",
    "\n",
    "print('Train series shape:', x_train.shape)\n",
    "print('Train reference shape:', y_train.shape)\n",
    "print('Validate series shape:', x_test.shape)\n",
    "print('Valdiate reference shape:', y_test.shape)\n",
    "\n",
    "training_samples_series = None\n",
    "training_samples_truth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.000005),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"./logs/\" + identifier\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(x_train, to_categorical(y_train),\n",
    "          validation_data=(x_test, to_categorical(y_test)),\n",
    "          batch_size=batch_size,\n",
    "          epochs=50,\n",
    "          verbose=2,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict(x_test,\n",
    "                     batch_size=256,\n",
    "                     verbose=1,\n",
    "                     steps=None,\n",
    "                     callbacks=None,\n",
    "                     max_queue_size=10,\n",
    "                     workers=2,\n",
    "                     use_multiprocessing=True)\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, prob[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.grid(True)\n",
    "plt.xlim(0,)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./models/LSTM'):\n",
    "    makedirs('./models/LSTM')\n",
    "\n",
    "model.save('./models/LSTM/training.LSTM.{}.h5'.format(identifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "print('Elapsed time: %.3f minutes' % ((t2-t1)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
